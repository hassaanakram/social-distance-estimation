{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47N0BLSqVwOH"
   },
   "source": [
    "### Change the path according to your google drive directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Parametres:\n",
    "    draw_lines: set this to False to only show Bounding boxes\n",
    "    iou_threshold: a yolo parameter. you can play with it to see how it affects detections\n",
    "    score_threshold: Since every detection has a score associated with it (between 0 and 1), this paramter sets the minimum score\n",
    "    for a detection to be counted\n",
    "'''\n",
    "draw_lines = False\n",
    "iou_threshold = 0.1\n",
    "score_threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1609304393605,
     "user": {
      "displayName": "Muhammad Hassaan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjnBHdRvV5F-uZMd4JkgMUjJ3k2M2hNF-Y1BauW=s64",
      "userId": "03702731417922112339"
     },
     "user_tz": -300
    },
    "id": "KbJOUX1AV8Fe",
    "outputId": "3b730c69-bf1a-4127-b3ff-c0ca6eba7702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\Desktop\\Upwork\\Social distancing\\social-distance-estimation\\TensorFlow-2.x-YOLOv3\n"
     ]
    }
   ],
   "source": [
    "%cd TensorFlow-2.x-YOLOv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s8PSfy52Sk_M"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# Change it according to your system\n",
    "repo_path = '/content/drive/MyDrive/Colab Notebooks/Upwork/Social distance/TensorFlow-2.x-YOLOv3'\n",
    "sys.path.insert(1, repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6143,
     "status": "ok",
     "timestamp": 1609304075606,
     "user": {
      "displayName": "Muhammad Hassaan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjnBHdRvV5F-uZMd4JkgMUjJ3k2M2hNF-Y1BauW=s64",
      "userId": "03702731417922112339"
     },
     "user_tz": -300
    },
    "id": "p-ONlX-WWQ3A"
   },
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from scipy.spatial import distance\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1598,
     "status": "ok",
     "timestamp": 1609304084963,
     "user": {
      "displayName": "Muhammad Hassaan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjnBHdRvV5F-uZMd4JkgMUjJ3k2M2hNF-Y1BauW=s64",
      "userId": "03702731417922112339"
     },
     "user_tz": -300
    },
    "id": "_fS8-Vxk_3oP",
    "outputId": "4d134211-61d7-47eb-aeec-43af2423397e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Please make sure that it is 2.4.0 \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7d9H3dMtYoED"
   },
   "outputs": [],
   "source": [
    "# YOLOv4 Imports (ignore the v3 name in folder structure)\n",
    "from yolov3.utils import Load_Yolo_model, image_preprocess, postprocess_boxes, nms, draw_bbox_lines, read_class_names\n",
    "from yolov3.configs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Niic482rYx21"
   },
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "def compute_midpoint(p1, p2):\n",
    "    '''Helper function to compute midpoint of two points\n",
    "       Where each point is a tuple of integers\n",
    "       Returns:\n",
    "            list(p1[0]+p2[0]/2, p1[1]+p2[1]/2)\n",
    "     '''\n",
    "    mpX = (p1[0]+p2[0])/2\n",
    "    mpY = (p1[1]+p2[1])/2\n",
    "    return np.array([mpX, mpY], dtype=np.int16)\n",
    "\n",
    "def compute_centroid(box):\n",
    "    '''Helper function to compute centroid of box.\n",
    "     Arguments:\n",
    "            box: 1x4 np array of form:\n",
    "                 box[0]: x1, box[1]: y1\n",
    "                 box[2]: x2, box[3]: y2\n",
    "     Returns: \n",
    "           nparray(centroidX, centroidY)\n",
    "  '''\n",
    "    return compute_midpoint((box[0], box[1]),(box[2], box[3]))\n",
    "\n",
    "def convert_wh(box):\n",
    "    '''Helper function to convert bbox to the width/height form:\n",
    "     [width, height, centre]\n",
    "     Arguments:\n",
    "              box: 1x4 np array of form:\n",
    "                   box[0]: x1, box[1]: y1\n",
    "                   box[2]: x2, box[3]: y2\n",
    "     Returns:\n",
    "            nparray([width, height, centre])\n",
    "  '''\n",
    "    width = box[2]-box[0]\n",
    "    height = box[3]-box[1]\n",
    "    centre = compute_centroid(box)\n",
    "    return np.array([width, height, centre], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JBRdR_hya2uj"
   },
   "outputs": [],
   "source": [
    "# Process input function\n",
    "def get_bboxes(Yolo, frame, input_size, score_threshold, iou_threshold):\n",
    "    '''Process the input video and return bboxes in two point and w, h, c form\n",
    "    frame: nd array of shape (height, width, channels)\n",
    "  Returns:\n",
    "     bboxes: list of bouding boxes in two point form\n",
    "     bboxes_centroidForm: list of bboxes in w, h, c form\n",
    "  '''\n",
    "    try:\n",
    "    # Change colour space\n",
    "        original_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        original_frame = cv2.cvtColor(original_frame, cv2.COLOR_BGR2RGB)\n",
    "    except:\n",
    "        print('Exception while converting colour space. Returning')\n",
    "        return\n",
    "    \n",
    "  # Preprocess as per YOLO's requirements\n",
    "    image_data = image_preprocess(np.copy(original_frame),\n",
    "                                [input_size, input_size])\n",
    "    image_data = image_data[np.newaxis,...].astype(np.float32)\n",
    "\n",
    "    # Get predictions\n",
    "    pred_bbox = Yolo.predict(image_data)\n",
    "\n",
    "    # Process the pred_bbox\n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "    bboxes = postprocess_boxes(pred_bbox, original_frame, input_size,\n",
    "                                 score_threshold)\n",
    "    bboxes = nms(bboxes, iou_threshold, method='nms')\n",
    "    \n",
    "    scores = list(map(lambda x: x[4], bboxes))\n",
    "    # Get width,heigth,centroid form\n",
    "    bboxes_centroidForm = list(map(convert_wh, bboxes))\n",
    "  \n",
    "    return bboxes, bboxes_centroidForm, scores\n",
    "\n",
    "def get_ppi(bboxes_whc, width, height):\n",
    "    '''get_ppi function returns the pixels per inch for the reference object.\n",
    "     Arguments:\n",
    "              bboxes_whc: bounding boxes list in width,height,centroid form\n",
    "     Returns:\n",
    "              ppi: pixels per inch\n",
    "  '''\n",
    "    approx_width_feet = 2\n",
    "    centre = (int(width/2), int(height/2))\n",
    "    centroids = list(map(lambda x: tuple(x[2]), bboxes_whc))\n",
    "    distances = list(map(lambda x: distance.euclidean(centre, x), centroids))\n",
    "    idx_middle = distances.index(min(distances))\n",
    "    \n",
    "    width_middle = bboxes_whc[idx_middle][0]\n",
    "    print(\"WIDTH OF MIDDLE GUY IN THIS FRAME: {}\".format(width_middle))\n",
    "    return width_middle/approx_width_feet, idx_middle\n",
    "\n",
    "\n",
    "def compute_distances(bboxes_whc, ppi):\n",
    "    '''To calculate distance between all detected persons without repetitions\n",
    "     Arguments:\n",
    "              bboxes_whc: bounding boxes of form (width, height, centroid)\n",
    "     Returns:\n",
    "              distances = list(all distance)\n",
    "              combinations\n",
    "              centroids\n",
    "  '''\n",
    "    distances = []\n",
    "    centroids = list(map(lambda x: tuple(x[2]), bboxes_whc))\n",
    "\n",
    "    # Combinations\n",
    "    list_combinations = list(itertools.combinations(centroids, 2))\n",
    "  \n",
    "    for i, pair in enumerate(list_combinations):\n",
    "        distances.append(distance.euclidean(pair[0], pair[1])/ppi)\n",
    "    return distances, list(itertools.combinations(list(range(len(centroids))), 2)), centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lFx191onU2XD"
   },
   "outputs": [],
   "source": [
    "def process_video(input_video, output_path, fps):\n",
    "    '''Process input function to perform detectios, overlays\n",
    "  '''\n",
    "    # Set some detection parameters\n",
    "    #iou_threshold = 0.1\n",
    "    #score_threshold = 0.40\n",
    "    input_size = 416\n",
    "    # Number of frames \n",
    "    N = input_video.shape[0]\n",
    "\n",
    "    # Get frame dimensions and set codec info\n",
    "    width = input_video.shape[2]\n",
    "    height = input_video.shape[1]\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, codec, fps,\n",
    "                        (width,height))\n",
    "    yolo = Load_Yolo_model()\n",
    "    \n",
    "    # Start reading frames\n",
    "    for i in range(N):\n",
    "        frame = input_video[i, :,:,:]\n",
    "        bboxes, bboxes_whc, scores = get_bboxes(yolo, frame, input_size, score_threshold,\n",
    "                                        iou_threshold)\n",
    "        if len(bboxes) == 0:\n",
    "            print(\"No detections in frame {}\".format(i))\n",
    "            continue\n",
    "        else:\n",
    "            print(\"frame {}, detections {}\".format(i, len(bboxes)))\n",
    "        # Calculate ppi and distances only if draw_lines is set\n",
    "        if draw_lines:\n",
    "            ppi, idx_middle = get_ppi(bboxes_whc, width, height)\n",
    "            distances, combinations, centroids = compute_distances(bboxes_whc, ppi)\n",
    "            frame = draw_bbox_lines(frame, bboxes, combinations, distances, centroids, draw_lines=True)\n",
    "        else:\n",
    "             frame = draw_bbox_lines(frame, bboxes, draw_lines=False)   \n",
    "        \n",
    "    \n",
    "        out.write(frame)\n",
    "  \n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(input_path, output_path):\n",
    "    frame = cv2.imread(input_path)\n",
    "    # Set some detection parameters\n",
    "    #iou_threshold = 0.1\n",
    "    #score_threshold = 0.40\n",
    "    input_size = 416\n",
    "    yolo = Load_Yolo_model()\n",
    "    num_violations = 0\n",
    "    \n",
    "    bboxes, bboxes_whc, scores = get_bboxes(yolo, frame, input_size, score_threshold,\n",
    "                                     iou_threshold)\n",
    "    if len(bboxes) == 0:\n",
    "        print(\"No detections in image\")\n",
    "    else:\n",
    "        print(\"# detections {}\".format(len(bboxes)))\n",
    "    # Calculate ppi and distances only if required\n",
    "    if draw_lines:\n",
    "        ppi, idx_middle = get_ppi(bboxes_whc, frame.shape[1], frame.shape[0])\n",
    "        distances, combinations, centroids = compute_distances(bboxes_whc, ppi)\n",
    "        frame = draw_bbox_lines(frame, bboxes, combinations, distances, centroids, draw_lines=True)\n",
    "    else:\n",
    "        frame = draw_bbox_lines(frame, bboxes, draw_lines=False)\n",
    "\n",
    "    \n",
    "    cv2.imwrite(output_path, frame)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Darknet_weights from: model_data/yolov4.weights\n",
      "# detections 1\n"
     ]
    }
   ],
   "source": [
    "process_image('c:/users/moham/desktop/Upwork/Social distancing/hh.jpg','c:/users/moham/desktop/Upwork/Social distancing/egimg_out.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ei9bAI4WWRSL"
   },
   "source": [
    "### Change the filepath in VideoCapture to your video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZddmV9gaayYn"
   },
   "outputs": [],
   "source": [
    "# Test bench\n",
    "cap = cv2.VideoCapture('c:/users/moham/desktop/upwork/social distancing/social-distance-estimation/v2.mp4')\n",
    "frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameCount = 10\n",
    "frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "buf = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n",
    "fc = 0\n",
    "ret = True\n",
    "\n",
    "while (fc < frameCount and ret):\n",
    "    ret, buf[fc] = cap.read()\n",
    "    fc += 1\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcACwVksWWDT"
   },
   "source": [
    "### Set the output path in the second argument of process_input. Make sure that it ends in .mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3u3LqXcna46f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Darknet_weights from: model_data/yolov4.weights\n",
      "frame 0, detections 7\n",
      "frame 1, detections 7\n",
      "frame 2, detections 6\n",
      "frame 3, detections 7\n",
      "frame 4, detections 7\n",
      "frame 5, detections 7\n",
      "frame 6, detections 8\n",
      "frame 7, detections 7\n",
      "frame 8, detections 6\n",
      "frame 9, detections 6\n"
     ]
    }
   ],
   "source": [
    "process_video(buf, 'c:/users/moham/desktop/upwork/social distancing/social-distance-estimation/v2_out.mp4', fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPffa8j/2qdGjMa2ZH5YlKr",
   "collapsed_sections": [],
   "mount_file_id": "1QXrVkDiU2sxcNNBWtV_By366GJzJlMON",
   "name": "Social Distance Analyzer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
