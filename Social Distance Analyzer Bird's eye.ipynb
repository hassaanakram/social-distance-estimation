{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47N0BLSqVwOH"
   },
   "source": [
    "### Change the path according to your google drive directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Parametres:\n",
    "    img_scale: percentage resizing of image\n",
    "    draw_lines: set this to False to only show Bounding boxes\n",
    "    iou_threshold: a yolo parameter. you can play with it to see how it affects detections\n",
    "    score_threshold: Since every detection has a score associated with it (between 0 and 1), this parameter sets the minimum score\n",
    "    for a detection to be counted\n",
    "'''\n",
    "img_scale = 0.4\n",
    "draw_lines = True\n",
    "distance_threshold = 1.83 # Metres\n",
    "iou_threshold = 0.1\n",
    "score_threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6143,
     "status": "ok",
     "timestamp": 1609304075606,
     "user": {
      "displayName": "Muhammad Hassaan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjnBHdRvV5F-uZMd4JkgMUjJ3k2M2hNF-Y1BauW=s64",
      "userId": "03702731417922112339"
     },
     "user_tz": -300
    },
    "id": "p-ONlX-WWQ3A"
   },
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import tensorflow as tf\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from scipy.spatial import distance\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1598,
     "status": "ok",
     "timestamp": 1609304084963,
     "user": {
      "displayName": "Muhammad Hassaan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjnBHdRvV5F-uZMd4JkgMUjJ3k2M2hNF-Y1BauW=s64",
      "userId": "03702731417922112339"
     },
     "user_tz": -300
    },
    "id": "_fS8-Vxk_3oP",
    "outputId": "4d134211-61d7-47eb-aeec-43af2423397e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Please make sure that it is 2.4.0 \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7d9H3dMtYoED"
   },
   "outputs": [],
   "source": [
    "# YOLOv4 Imports (ignore the v3 name in folder structure)\n",
    "from yolov3.utils import Load_Yolo_model, image_preprocess, postprocess_boxes, nms, draw_detections, read_class_names\n",
    "from yolov3.configs import *\n",
    "import calibrate_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Niic482rYx21"
   },
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "def compute_midpoint(p1, p2):\n",
    "    '''Helper function to compute midpoint of two points\n",
    "       Where each point is a tuple of integers\n",
    "       Returns:\n",
    "            list(p1[0]+p2[0]/2, p1[1]+p2[1]/2)\n",
    "     '''\n",
    "    mpX = (p1[0]+p2[0])/2\n",
    "    mpY = (p1[1]+p2[1])/2\n",
    "    return np.array([mpX, mpY], dtype=np.int16)\n",
    "\n",
    "def compute_centroid(box):\n",
    "    '''Helper function to compute centroid of box.\n",
    "     Arguments:\n",
    "            box: 1x4 np array of form:\n",
    "                 box[0]: x1, box[1]: y1\n",
    "                 box[2]: x2, box[3]: y2\n",
    "     Returns: \n",
    "           nparray(centroidX, centroidY)\n",
    "  '''\n",
    "    return compute_midpoint((box[0], box[1]),(box[2], box[3]))\n",
    "\n",
    "def convert_xc(box):\n",
    "    '''Helper function to convert bbox to the x-coord,centroid form:\n",
    "     [x1, x2, centre] This will be used to easily access x coords in\n",
    "     ppm calculation function.\n",
    "     Arguments:\n",
    "              box: 1x4 np array of form:\n",
    "                   box[0]: x1, box[1]: y1\n",
    "                   box[2]: x2, box[3]: y2\n",
    "     Returns:\n",
    "            nparray([x1, x2, centre])\n",
    "  '''\n",
    "    centre = compute_centroid(box)\n",
    "    return np.array([box[0], box[2], centre], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JBRdR_hya2uj"
   },
   "outputs": [],
   "source": [
    "# Process input function\n",
    "def get_bboxes(Yolo, frame, input_size, score_threshold, iou_threshold, limits):\n",
    "    '''Process the input video and return bboxes in two point and w, h, c form\n",
    "    frame: nd array of shape (height, width, channels)\n",
    "  Returns:\n",
    "     bboxes: list of bouding boxes in two point form\n",
    "     bboxes_centroidForm: list of bboxes in w, h, c form\n",
    "  '''\n",
    "    try:\n",
    "    # Change colour space\n",
    "        original_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        original_frame = cv2.cvtColor(original_frame, cv2.COLOR_BGR2RGB)\n",
    "    except:\n",
    "        print('Exception while converting colour space. Returning')\n",
    "        return\n",
    "    \n",
    "    # Preprocess as per YOLO's requirements\n",
    "    image_data = image_preprocess(np.copy(original_frame),\n",
    "                                [input_size, input_size])\n",
    "    image_data = image_data[np.newaxis,...].astype(np.float32)\n",
    "\n",
    "    # Get predictions\n",
    "    pred_bbox = Yolo.predict(image_data)\n",
    "\n",
    "    # Process the pred_bbox\n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "    bboxes = postprocess_boxes(pred_bbox, original_frame, input_size,\n",
    "                                 score_threshold)\n",
    "    bboxes = nms(bboxes, iou_threshold, method='nms', limits=limits)\n",
    "    \n",
    "    scores = list(map(lambda x: x[4], bboxes))\n",
    "    # Get x Coord, centre form of bboxes\n",
    "    bboxes_centroidForm = list(map(convert_xc, bboxes))\n",
    "  \n",
    "    return bboxes, bboxes_centroidForm, scores\n",
    "\n",
    "def get_ppm(bboxes_xc, width, height, matrix):\n",
    "    '''get_ppm function returns the pixels per metre for the reference object.\n",
    "     Arguments:\n",
    "              bboxes_xc: bounding boxes list in width,height,centroid form\n",
    "     Returns:\n",
    "              ppm: pixels per metre\n",
    "              idx_middle: Index of middle person in bboxes\n",
    "  '''\n",
    "    # The average width of a person in metres\n",
    "    approx_width_metre = 0.40\n",
    "    # Centre point of input image\n",
    "    centre = (int(width/2), int(height/2))\n",
    "    # Fetch centroids\n",
    "    centroids = list(map(lambda x: tuple(x[2]), bboxes_xc))\n",
    "    distances = list(map(lambda x: distance.euclidean(centre, x), centroids))\n",
    "    idx_middle = distances.index(min(distances))\n",
    "    \n",
    "    x1_middle, x2_middle = int(bboxes_xc[idx_middle][0]), int(bboxes_xc[idx_middle][1])\n",
    "    x_coords = [[[x1_middle, x2_middle]]]\n",
    "    print(\"XCOORDS OF MIDDLE GUY IN OG FRAME: {}\".format(x_coords))\n",
    "    x_coordsTransformed = cv2.perspectiveTransform(np.float32(x_coords), matrix) # This returns a (1,1,2) np array\n",
    "    print(\"TRANSFORMED XCOORDS: {}\".format(x_coordsTransformed))\n",
    "    #width_middle = x_coordsTransformed[0,0,1] - x_coordsTransformed[0,0,0]\n",
    "    width_middle = x2_middle - x1_middle\n",
    "    ppm = width_middle/approx_width_metre\n",
    "    print(\"WIDTH OF MIDDLE GUY IN ORIGINAL FRAME: {}\".format(x2_middle-x1_middle))\n",
    "    #print(\"WIDTH OF MIDDLE GUY IN TRANSFORMED FRAME: {}\".format(width_middle))\n",
    "    print(\"Pixels per Metre using approx width {}: {}\".format(approx_width_metre, ppm))\n",
    "    return ppm, idx_middle\n",
    "\n",
    "\n",
    "def compute_distances(bboxes_xc, ppm, matrix):\n",
    "    '''To calculate distance between all detected persons without repetitions\n",
    "     Arguments:\n",
    "              bboxes_xc: bounding boxes of form (x1, x2, centroid)\n",
    "     Returns:\n",
    "              distances = list(all distance)\n",
    "              combinations\n",
    "              centroids\n",
    "  '''\n",
    "    distances = []\n",
    "    # Returns a list of form [[cx1, cy1], [cx2, cy2],...,[cxn, cyn]]\n",
    "    centroids = list(map(lambda x: x[2], bboxes_xc))\n",
    "    # Transforming centroids\n",
    "    centroids_transformed = np.squeeze(cv2.perspectiveTransform(np.float32([centroids]), matrix))\n",
    "    centroids_transformed = list(map(lambda x: tuple(x), centroids_transformed))\n",
    "    # Combinations\n",
    "    list_combinations = list(itertools.combinations(centroids_transformed, 2))\n",
    "  \n",
    "    for i, pair in enumerate(list_combinations):\n",
    "        distances.append(distance.euclidean(pair[0], pair[1])/ppm)\n",
    "    return distances, list(itertools.combinations(list(range(len(centroids))), 2)), list(map(lambda x: tuple(x[2]), bboxes_xc)), centroids_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lFx191onU2XD"
   },
   "outputs": [],
   "source": [
    "def process_video(input_video, output_path, fps):\n",
    "    '''Process input function to perform detectios, overlays\n",
    "       output_path1: Main video\n",
    "       output_path2: Birds eye view\n",
    "  '''\n",
    "    # Set some detection parameters\n",
    "    input_size = 416\n",
    "    # Number of frames \n",
    "    N = input_video.shape[0]\n",
    "    \n",
    "    # First frame for calibration\n",
    "    frame = input_video[0, :,:,:]\n",
    "    \n",
    "    # Get transformation matrix \n",
    "    matrix, inv_matrix, list_points = calibrate_frame.calibrate(frame)\n",
    "    \n",
    "    # max_limits = [[minx, miny], [maxx, maxy]]\n",
    "    limits =  [[min(list(map(lambda x: x[0], list_points))), min(list(map(lambda x: x[1], list_points)))],\n",
    "                   [max(list(map(lambda x: x[0], list_points))), max(list(map(lambda x: x[1], list_points)))]]\n",
    "    \n",
    "    # Get frame dimensions and set codec info\n",
    "    width = input_video.shape[2]\n",
    "    height = input_video.shape[1]\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path+'Main.mp4', codec, fps,\n",
    "                        (width,height))\n",
    "    out_bird = cv2.VideoWriter(output_path+'Birdseye.mp4', codec, fps, (width,height))\n",
    "    yolo = Load_Yolo_model()\n",
    "    ppm = None\n",
    "    \n",
    "    # Start reading frames\n",
    "    for i in range(N):\n",
    "        # Birdseye\n",
    "        birds_eye = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        # OG Frame\n",
    "        frame = input_video[i, :,:,:]\n",
    "        # Get bounding boxes from yolov4\n",
    "        bboxes, bboxes_xc, scores = get_bboxes(yolo, frame, input_size, score_threshold,\n",
    "                                        iou_threshold, limits)\n",
    "        \n",
    "        if len(bboxes) == 0:\n",
    "            print(\"No detections in frame {}\".format(i))\n",
    "            continue\n",
    "        else:\n",
    "            print(\"frame {}, detections {}\".format(i, len(bboxes)))\n",
    "            \n",
    "        # Calculate ppm and distances only if draw_lines is set\n",
    "        if draw_lines:\n",
    "            if ppm == None:\n",
    "                ppm, idx_middle = get_ppm(bboxes_xc, frame.shape[1], frame.shape[0], matrix)\n",
    "            distances, combinations, centroids, centroids_transformed = compute_distances(bboxes_xc, ppm, matrix)\n",
    "            frame, birds_eye = draw_detections(frame, bboxes, birds_eye, combinations, distances, centroids, centroids_transformed,\n",
    "                                              distance_threshold)\n",
    "        else:\n",
    "             frame = draw_bbox(frame, bboxes)   \n",
    "        \n",
    "    \n",
    "        out.write(frame)\n",
    "        out_bird.write(birds_eye)\n",
    "        cv2.imshow('OG Frame', frame)\n",
    "        cv2.imshow('Birds Eye', birds_eye)\n",
    "        cv2.waitKey(1000)\n",
    "        \n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(input_path, output_path):\n",
    "    frame = cv2.imread(input_path)\n",
    "    frame = cv2.resize(frame, (int(frame.shape[1]*img_scale), int(frame.shape[0]*img_scale)))\n",
    "    \n",
    "    # Birdseye\n",
    "    birds_eye = np.zeros((frame.shape[0], frame.shape[1], 3), dtype=np.uint8)\n",
    "    # Set some detection parameters\n",
    "    input_size = 416\n",
    "    yolo = Load_Yolo_model()\n",
    "    \n",
    "    # Get transformation matrix \n",
    "    matrix, inv_matrix, list_points = calibrate_frame.calibrate(frame)\n",
    "    # max_limits = [[minx, miny], [maxx, maxy]]\n",
    "    limits =  [[min(list(map(lambda x: x[0], list_points))), min(list(map(lambda x: x[1], list_points)))],\n",
    "                   [max(list(map(lambda x: x[0], list_points))), max(list(map(lambda x: x[1], list_points)))]]\n",
    "  \n",
    "    # Get bounding boxes from yolov4\n",
    "    bboxes, bboxes_xc, scores = get_bboxes(yolo, frame, input_size, score_threshold,\n",
    "                                     iou_threshold, limits)\n",
    "    if len(bboxes) == 0:\n",
    "        print(\"No detections in image returning\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"# detections {}\".format(len(bboxes)))\n",
    "    \n",
    "    # Calculate ppm and distances only if required\n",
    "    if draw_lines:\n",
    "        ppm, idx_middle = get_ppm(bboxes_xc, frame.shape[1], frame.shape[0], matrix)\n",
    "        distances, combinations, centroids, centroids_transformed = compute_distances(bboxes_xc, ppm, matrix)\n",
    "        frame, birds_eye = draw_detections(frame, bboxes, birds_eye, combinations, distances, centroids, centroids_transformed,\n",
    "                                              distance_threshold)\n",
    "    else:\n",
    "        frame = draw_bbox(frame, bboxes)\n",
    "        \n",
    "    # Save images\n",
    "    cv2.imwrite(output_path+'Main.jpg', frame)\n",
    "    cv2.imwrite(output_path+'birdseye.jpg', birds_eye)\n",
    "    \n",
    "    # Display both images\n",
    "    cv2.imshow('OG Frame', frame)\n",
    "    cv2.imshow('Birds Eye', birds_eye)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ei9bAI4WWRSL"
   },
   "source": [
    "### Change the filepath in according to the input image/video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Darknet_weights from: model_data/yolov4.weights\n",
      "Calibration started\n",
      "Width,Height of frame: (780,520)\n",
      "Left Mouse click at ( 21 , 95 )\n",
      "Left Mouse click at ( 496 , 112 )\n",
      "Left Mouse click at ( 13 , 510 )\n",
      "Left Mouse click at ( 554 , 503 )\n",
      "Image to birds eye matrix: [[ 1.59855506e+00  3.08155193e-02 -3.64971307e+01]\n",
      " [-5.30414761e-02  1.48204124e+00 -1.39680047e+02]\n",
      " [-1.34177752e-04  3.63418137e-04  1.00000000e+00]]\n",
      "Birds eye to image matrix: [[ 6.46545466e-01 -1.85928801e-02  2.10000000e+01]\n",
      " [ 3.02786701e-02  6.72214230e-01  9.50000000e+01]\n",
      " [ 7.57481995e-05 -2.46789594e-04  1.00000000e+00]]\n",
      "# detections 2\n",
      "XCOORDS OF MIDDLE GUY IN OG FRAME: [[[207, 261]]]\n",
      "TRANSFORMED XCOORDS: [[[283.43457 221.30835]]]\n",
      "WIDTH OF MIDDLE GUY IN ORIGINAL FRAME: 54\n",
      "Pixels per Metre using approx width 0.4: 135.0\n"
     ]
    }
   ],
   "source": [
    "# For image\n",
    "process_image('c:/users/moham/desktop/Upwork/Social distancing/Samples/testim5.png','c:/users/moham/desktop/Upwork/Social distancing/Outputs/testim5Out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ZddmV9gaayYn"
   },
   "outputs": [],
   "source": [
    "# For video\n",
    "cap = cv2.VideoCapture('c:/users/moham/desktop/upwork/social distancing/Samples/PETS2009.avi')\n",
    "frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frameCount = 30\n",
    "buf = np.empty((frameCount, int(frameHeight*img_scale), int(frameWidth*img_scale), 3), np.dtype('uint8'))\n",
    "fc = 0\n",
    "ret = True\n",
    "\n",
    "while (fc < frameCount and ret):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (int(frameWidth*img_scale), int(frameHeight*img_scale)))\n",
    "    buf[fc] = frame\n",
    "    fc += 1\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 230, 307, 3)\n"
     ]
    }
   ],
   "source": [
    "print(buf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcACwVksWWDT"
   },
   "source": [
    "### Set the output path in the second argument of process_input. Make sure that it ends in .mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3u3LqXcna46f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration started\n",
      "Width,Height of frame: (307,230)\n",
      "Left Mouse click at ( 94 , 46 )\n",
      "Left Mouse click at ( 297 , 88 )\n",
      "Left Mouse click at ( 46 , 194 )\n",
      "Left Mouse click at ( 252 , 215 )\n",
      "Image to birds eye matrix: [[ 1.13622211e+00  3.68504467e-01 -1.23756084e+02]\n",
      " [-2.74960822e-01  1.32897731e+00 -3.52866389e+01]\n",
      " [-5.74377586e-04 -3.14574722e-04  1.00000000e+00]]\n",
      "Birds eye to image matrix: [[ 8.17877613e-01 -2.04534365e-01  9.40000000e+01]\n",
      " [ 1.83219619e-01  6.61028035e-01  4.60000000e+01]\n",
      " [ 5.27406830e-04  9.04627555e-05  1.00000000e+00]]\n",
      "Loading Darknet_weights from: model_data/yolov4.weights\n",
      "frame 0, detections 3\n",
      "XCOORDS OF MIDDLE GUY IN OG FRAME: [[[102, 122]]]\n",
      "TRANSFORMED XCOORDS: [[[ 41.07936 109.41165]]]\n",
      "WIDTH OF MIDDLE GUY IN ORIGINAL FRAME: 20\n",
      "Pixels per Metre using approx width 0.4: 50.0\n",
      "frame 1, detections 3\n",
      "frame 2, detections 4\n",
      "frame 3, detections 4\n",
      "frame 4, detections 3\n",
      "frame 5, detections 3\n",
      "frame 6, detections 3\n",
      "frame 7, detections 3\n",
      "frame 8, detections 3\n",
      "frame 9, detections 3\n",
      "frame 10, detections 3\n",
      "frame 11, detections 3\n",
      "frame 12, detections 3\n",
      "frame 13, detections 3\n"
     ]
    }
   ],
   "source": [
    "process_video(buf[:, :,:,:], 'c:/users/moham/desktop/upwork/social distancing/outputs/PETS2009out', fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPffa8j/2qdGjMa2ZH5YlKr",
   "collapsed_sections": [],
   "mount_file_id": "1QXrVkDiU2sxcNNBWtV_By366GJzJlMON",
   "name": "Social Distance Analyzer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
