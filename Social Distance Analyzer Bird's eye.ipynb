{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47N0BLSqVwOH"
   },
   "source": [
    "### Change the path according to your google drive directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file calibrate_frame.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create empty list of points for coords\n",
    "list_points = list()\n",
    "\n",
    "# Define the callback function that we are going to use to get coords\n",
    "def CallBackFunc(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        param = cv2.circle(param,(x,y),5,(0,255,0),-1)\n",
    "        print(\"Left Mouse click at (\", x, \",\", y, \")\")\n",
    "        list_points.append([x,y])\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "        param = cv2.circle(param,(x,y),5,(0,255,0),-1)\n",
    "        print(\"Right Mouse click at (\", x, \",\", y, \")\")\n",
    "        list_points.append([x,y])\n",
    "\n",
    "        \n",
    "def calibrate(frame):\n",
    "    # Create a blank window\n",
    "    global list_points\n",
    "    list_points = list()\n",
    "    print(\"Calibration started\")\n",
    "    windowName = 'MouseCallback'\n",
    "    cv2.namedWindow(windowName)\n",
    "\n",
    "    # Get the size of input frame\n",
    "    height, width, _ = frame.shape\n",
    "    print(\"Width,Height of frame: ({},{})\".format(width, height))\n",
    "    # Bind callback function to window\n",
    "    cv2.setMouseCallback(windowName, CallBackFunc, frame)\n",
    "\n",
    "    # Check if 4 points have been saved\n",
    "    while (True):\n",
    "        cv2.imshow(windowName, frame)\n",
    "        cv2.waitKey(10) & 0xFF\n",
    "        \n",
    "        if len(list_points) == 4:\n",
    "            break\n",
    "        if cv2.waitKey(20) == 27:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Calculating projection matrix\n",
    "    src_pts = np.float32(list_points)\n",
    "    dest_pts = np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
    "\n",
    "    matrix = cv2.getPerspectiveTransform(src_pts, dest_pts)\n",
    "    print(\"Image to birds eye matrix: {}\".format(matrix))\n",
    "    inv_matrix = cv2.getPerspectiveTransform(dest_pts, src_pts)\n",
    "    print(\"Birds eye to image matrix: {}\".format(inv_matrix))\n",
    "    return matrix, inv_matrix, list_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Parametres:\n",
    "    img_scale: percentage resizing of image\n",
    "    draw_lines: set this to False to only show Bounding boxes\n",
    "    iou_threshold: a yolo parameter. you can play with it to see how it affects detections\n",
    "    score_threshold: Since every detection has a score associated with it (between 0 and 1), this parameter sets the minimum score\n",
    "    for a detection to be counted\n",
    "'''\n",
    "img_scale = 0.4\n",
    "draw_lines = True\n",
    "distance_threshold = 1.83 # Metres\n",
    "iou_threshold = 0.1\n",
    "score_threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6143,
     "status": "ok",
     "timestamp": 1609304075606,
     "user": {
      "displayName": "Muhammad Hassaan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjnBHdRvV5F-uZMd4JkgMUjJ3k2M2hNF-Y1BauW=s64",
      "userId": "03702731417922112339"
     },
     "user_tz": -300
    },
    "id": "p-ONlX-WWQ3A"
   },
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import tensorflow as tf\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from scipy.spatial import distance\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1598,
     "status": "ok",
     "timestamp": 1609304084963,
     "user": {
      "displayName": "Muhammad Hassaan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjnBHdRvV5F-uZMd4JkgMUjJ3k2M2hNF-Y1BauW=s64",
      "userId": "03702731417922112339"
     },
     "user_tz": -300
    },
    "id": "_fS8-Vxk_3oP",
    "outputId": "4d134211-61d7-47eb-aeec-43af2423397e"
   },
   "outputs": [],
   "source": [
    "# Please make sure that it is 2.4.0 \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7d9H3dMtYoED"
   },
   "outputs": [],
   "source": [
    "# YOLOv4 Imports (ignore the v3 name in folder structure)\n",
    "from yolov3.utils import Load_Yolo_model, image_preprocess, postprocess_boxes, nms, draw_bbox, draw_lines, draw_centroids, draw_detections, read_class_names\n",
    "from yolov3.configs import *\n",
    "import calibrate_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Niic482rYx21"
   },
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "def compute_midpoint(p1, p2):\n",
    "    '''Helper function to compute midpoint of two points\n",
    "       Where each point is a tuple of integers\n",
    "       Returns:\n",
    "            list(p1[0]+p2[0]/2, p1[1]+p2[1]/2)\n",
    "     '''\n",
    "    mpX = (p1[0]+p2[0])/2\n",
    "    mpY = (p1[1]+p2[1])/2\n",
    "    return np.array([mpX, mpY], dtype=np.int16)\n",
    "\n",
    "def compute_centroid(box):\n",
    "    '''Helper function to compute centroid of box.\n",
    "     Arguments:\n",
    "            box: 1x4 np array of form:\n",
    "                 box[0]: x1, box[1]: y1\n",
    "                 box[2]: x2, box[3]: y2\n",
    "     Returns: \n",
    "           nparray(centroidX, centroidY)\n",
    "  '''\n",
    "    return compute_midpoint((box[0], box[1]),(box[2], box[3]))\n",
    "\n",
    "def convert_xc(box):\n",
    "    '''Helper function to convert bbox to the x-coord,centroid form:\n",
    "     [x1, x2, centre] This will be used to easily access x coords in\n",
    "     ppm calculation function.\n",
    "     Arguments:\n",
    "              box: 1x4 np array of form:\n",
    "                   box[0]: x1, box[1]: y1\n",
    "                   box[2]: x2, box[3]: y2\n",
    "     Returns:\n",
    "            nparray([x1, x2, centre])\n",
    "  '''\n",
    "    centre = compute_centroid(box)\n",
    "    return np.array([box[0], box[2], centre], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBRdR_hya2uj"
   },
   "outputs": [],
   "source": [
    "# Process input function\n",
    "def get_bboxes(Yolo, frame, input_size, score_threshold, iou_threshold, limits):\n",
    "    '''Process the input video and return bboxes in two point and w, h, c form\n",
    "    frame: nd array of shape (height, width, channels)\n",
    "  Returns:\n",
    "     bboxes: list of bouding boxes in two point form\n",
    "     bboxes_centroidForm: list of bboxes in w, h, c form\n",
    "  '''\n",
    "    try:\n",
    "    # Change colour space\n",
    "        original_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        original_frame = cv2.cvtColor(original_frame, cv2.COLOR_BGR2RGB)\n",
    "    except:\n",
    "        print('Exception while converting colour space. Returning')\n",
    "        return\n",
    "    \n",
    "    # Preprocess as per YOLO's requirements\n",
    "    image_data = image_preprocess(np.copy(original_frame),\n",
    "                                [input_size, input_size])\n",
    "    image_data = image_data[np.newaxis,...].astype(np.float32)\n",
    "\n",
    "    # Get predictions\n",
    "    pred_bbox = Yolo.predict(image_data)\n",
    "\n",
    "    # Process the pred_bbox\n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "    bboxes = postprocess_boxes(pred_bbox, original_frame, input_size,\n",
    "                                 score_threshold)\n",
    "    bboxes = nms(bboxes, iou_threshold, method='nms', limits=limits)\n",
    "    \n",
    "    scores = list(map(lambda x: x[4], bboxes))\n",
    "    # Get x Coord, centre form of bboxes\n",
    "    bboxes_centroidForm = list(map(convert_xc, bboxes))\n",
    "  \n",
    "    return bboxes, bboxes_centroidForm, scores\n",
    "\n",
    "def get_ppm(bboxes_xc, width, height, matrix):\n",
    "    '''get_ppm function returns the pixels per metre for the reference object.\n",
    "     Arguments:\n",
    "              bboxes_xc: bounding boxes list in width,height,centroid form\n",
    "     Returns:\n",
    "              ppm: pixels per metre\n",
    "              idx_middle: Index of middle person in bboxes\n",
    "  '''\n",
    "    # The average width of a person in metres\n",
    "    approx_width_metre = 0.40\n",
    "    # Centre point of input image\n",
    "    centre = (int(width/2), int(height/2))\n",
    "    # Fetch centroids\n",
    "    centroids = list(map(lambda x: tuple(x[2]), bboxes_xc))\n",
    "    distances = list(map(lambda x: distance.euclidean(centre, x), centroids))\n",
    "    idx_middle = distances.index(min(distances))\n",
    "    \n",
    "    x1_middle, x2_middle = int(bboxes_xc[idx_middle][0]), int(bboxes_xc[idx_middle][1])\n",
    "    x_coords = [[[x1_middle, x2_middle]]]\n",
    "    print(\"XCOORDS OF MIDDLE GUY IN OG FRAME: {}\".format(x_coords))\n",
    "    x_coordsTransformed = cv2.perspectiveTransform(np.float32(x_coords), matrix) # This returns a (1,1,2) np array\n",
    "    print(\"TRANSFORMED XCOORDS: {}\".format(x_coordsTransformed))\n",
    "    #width_middle = x_coordsTransformed[0,0,1] - x_coordsTransformed[0,0,0]\n",
    "    width_middle = x2_middle - x1_middle\n",
    "    ppm = width_middle/approx_width_metre\n",
    "    print(\"WIDTH OF MIDDLE GUY IN ORIGINAL FRAME: {}\".format(x2_middle-x1_middle))\n",
    "    #print(\"WIDTH OF MIDDLE GUY IN TRANSFORMED FRAME: {}\".format(width_middle))\n",
    "    print(\"Pixels per Metre using approx width {}: {}\".format(approx_width_metre, ppm))\n",
    "    return ppm, idx_middle\n",
    "\n",
    "\n",
    "def compute_distances(bboxes_xc, ppm, matrix):\n",
    "    '''To calculate distance between all detected persons without repetitions\n",
    "     Arguments:\n",
    "              bboxes_xc: bounding boxes of form (x1, x2, centroid)\n",
    "     Returns:\n",
    "              distances = list(all distance)\n",
    "              combinations\n",
    "              centroids\n",
    "  '''\n",
    "    distances = []\n",
    "    # Returns a list of form [[cx1, cy1], [cx2, cy2],...,[cxn, cyn]]\n",
    "    centroids = list(map(lambda x: x[2], bboxes_xc))\n",
    "    # Transforming centroids\n",
    "    centroids_transformed = np.squeeze(cv2.perspectiveTransform(np.float32([centroids]), matrix))\n",
    "    centroids_transformed = list(map(lambda x: tuple(x), centroids_transformed))\n",
    "    # Combinations\n",
    "    list_combinations = list(itertools.combinations(centroids_transformed, 2))\n",
    "  \n",
    "    for i, pair in enumerate(list_combinations):\n",
    "        distances.append(distance.euclidean(pair[0], pair[1])/ppm)\n",
    "    return distances, list(itertools.combinations(list(range(len(centroids))), 2)), list(map(lambda x: tuple(x[2]), bboxes_xc)), centroids_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFx191onU2XD"
   },
   "outputs": [],
   "source": [
    "def process_video(input_video, output_path, fps):\n",
    "    '''Process input function to perform detectios, overlays\n",
    "  '''\n",
    "    # Set some detection parameters\n",
    "    input_size = 416\n",
    "    # Number of frames \n",
    "    N = input_video.shape[0]\n",
    "    \n",
    "    # First frame for calibration\n",
    "    frame = input_video[0, :,:,:]\n",
    "    \n",
    "    # Get transformation matrix \n",
    "    matrix, inv_matrix, list_points = calibrate_frame.calibrate(frame)\n",
    "    \n",
    "    # max_limits = [[minx, miny], [maxx, maxy]]\n",
    "    limits =  [[min(list(map(lambda x: x[0], list_points))), min(list(map(lambda x: x[1], list_points)))],\n",
    "                   [max(list(map(lambda x: x[0], list_points))), max(list(map(lambda x: x[1], list_points)))]]\n",
    "    \n",
    "    # Get frame dimensions and set codec info\n",
    "    width = input_video.shape[2]\n",
    "    height = input_video.shape[1]\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, codec, fps,\n",
    "                        (width,height))\n",
    "    out_bird = cv2.VideoWriter('c:/users/moham/desktop/upwork/social distancing/outputs/birds.mp4', codec, fps, (width,height))\n",
    "    yolo = Load_Yolo_model()\n",
    "    ppm = None\n",
    "    \n",
    "    # Start reading frames\n",
    "    for i in range(N):\n",
    "        # Birdseye\n",
    "        birds_eye = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        # OG Frame\n",
    "        frame = input_video[i, :,:,:]\n",
    "        # Get bounding boxes from yolov4\n",
    "        bboxes, bboxes_xc, scores = get_bboxes(yolo, frame, input_size, score_threshold,\n",
    "                                        iou_threshold, limits)\n",
    "        \n",
    "        if len(bboxes) == 0:\n",
    "            print(\"No detections in frame {}\".format(i))\n",
    "            continue\n",
    "        else:\n",
    "            print(\"frame {}, detections {}\".format(i, len(bboxes)))\n",
    "            \n",
    "        # Calculate ppm and distances only if draw_lines is set\n",
    "        if draw_lines:\n",
    "            if ppm == None:\n",
    "                ppm, idx_middle = get_ppm(bboxes_xc, frame.shape[1], frame.shape[0], matrix)\n",
    "            distances, combinations, centroids, centroids_transformed = compute_distances(bboxes_xc, ppm, matrix)\n",
    "            # Draw bounding boxes and lines on Original frame\n",
    "            #frame = draw_bbox(frame, bboxes, combinations, distances, centroids)\n",
    "            #frame = draw_lines(frame, distances, combinations, centroids, birds_eye=False)\n",
    "        \n",
    "            # Draw centroid points and lines on birds eye view\n",
    "            #birds_eye = draw_centroids(birds_eye, centroids)\n",
    "            #birds_eye = draw_lines(birds_eye, distances, combinations, centroids, birds_eye=True)\n",
    "            frame, birds_eye = draw_detections(frame, bboxes, birds_eye, combinations, distances, centroids, centroids_transformed,\n",
    "                                              distance_threshold)\n",
    "        else:\n",
    "             frame = draw_bbox(frame, bboxes)   \n",
    "        \n",
    "    \n",
    "        out.write(frame)\n",
    "        out_bird.write(birds_eye)\n",
    "        cv2.imshow('OG Frame', frame)\n",
    "        cv2.imshow('Birds Eye', birds_eye)\n",
    "        cv2.waitKey(1000)\n",
    "        \n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(input_path, output_path):\n",
    "    frame = cv2.imread(input_path)\n",
    "    frame = cv2.resize(frame, (int(frame.shape[1]*img_scale), int(frame.shape[0]*img_scale)))\n",
    "    \n",
    "    # Birdseye\n",
    "    birds_eye = np.zeros((frame.shape[0], frame.shape[1], 3), dtype=np.uint8)\n",
    "    # Set some detection parameters\n",
    "    input_size = 416\n",
    "    yolo = Load_Yolo_model()\n",
    "    \n",
    "    # Get transformation matrix \n",
    "    matrix, inv_matrix, list_points = calibrate_frame.calibrate(frame)\n",
    "    # max_limits = [[minx, miny], [maxx, maxy]]\n",
    "    limits =  [[min(list(map(lambda x: x[0], list_points))), min(list(map(lambda x: x[1], list_points)))],\n",
    "                   [max(list(map(lambda x: x[0], list_points))), max(list(map(lambda x: x[1], list_points)))]]\n",
    "  \n",
    "    # Get bounding boxes from yolov4\n",
    "    bboxes, bboxes_xc, scores = get_bboxes(yolo, frame, input_size, score_threshold,\n",
    "                                     iou_threshold, limits)\n",
    "    if len(bboxes) == 0:\n",
    "        print(\"No detections in image returning\")\n",
    "        return\n",
    "    else:\n",
    "        print(\"# detections {}\".format(len(bboxes)))\n",
    "    \n",
    "    # Calculate ppm and distances only if required\n",
    "    if draw_lines:\n",
    "        ppm, idx_middle = get_ppm(bboxes_xc, frame.shape[1], frame.shape[0], matrix)\n",
    "        distances, combinations, centroids, centroids_transformed = compute_distances(bboxes_xc, ppm, matrix)\n",
    "        # Draw bounding boxes and lines on Original frame\n",
    "        #frame = draw_bbox(frame, bboxes, combinations, distances, centroids)\n",
    "        #frame = draw_lines(frame, distances, combinations, centroids, birds_eye=False)\n",
    "        \n",
    "        # Draw centroid points and lines on birds eye view\n",
    "        #birds_eye = draw_centroids(birds_eye, centroids)\n",
    "        #birds_eye = draw_lines(birds_eye, distances, combinations, centroids, birds_eye=True)\n",
    "        frame, birds_eye = draw_detections(frame, bboxes, birds_eye, combinations, distances, centroids, centroids_transformed,\n",
    "                                              distance_threshold)\n",
    "    else:\n",
    "        frame = draw_bbox(frame, bboxes)\n",
    "        \n",
    "    # Display both images\n",
    "    cv2.imshow('OG Frame', frame)\n",
    "    cv2.imshow('Birds Eye', birds_eye)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ei9bAI4WWRSL"
   },
   "source": [
    "### Change the filepath in according to the input image/video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For image\n",
    "process_image('c:/users/moham/desktop/Upwork/Social distancing/Samples/testim5.png','c:/users/moham/desktop/Upwork/Social distancing/Outputs/testim5Out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZddmV9gaayYn"
   },
   "outputs": [],
   "source": [
    "# For video\n",
    "cap = cv2.VideoCapture('c:/users/moham/desktop/upwork/social distancing/Samples/PETS2009.avi')\n",
    "frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frameCount = 30\n",
    "buf = np.empty((frameCount, int(frameHeight*img_scale), int(frameWidth*img_scale), 3), np.dtype('uint8'))\n",
    "fc = 0\n",
    "ret = True\n",
    "\n",
    "while (fc < frameCount and ret):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (int(frameWidth*img_scale), int(frameHeight*img_scale)))\n",
    "    buf[fc] = frame\n",
    "    fc += 1\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(buf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcACwVksWWDT"
   },
   "source": [
    "### Set the output path in the second argument of process_input. Make sure that it ends in .mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3u3LqXcna46f"
   },
   "outputs": [],
   "source": [
    "process_video(buf[:, :,:,:], 'c:/users/moham/desktop/upwork/social distancing/outputs/PETS2009out.mp4', fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPffa8j/2qdGjMa2ZH5YlKr",
   "collapsed_sections": [],
   "mount_file_id": "1QXrVkDiU2sxcNNBWtV_By366GJzJlMON",
   "name": "Social Distance Analyzer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
